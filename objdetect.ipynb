{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detect\n",
    "\n",
    "https://github.com/Megvii-BaseDetection/YOLOX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DS1jv3-yXtM5"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from detector import *\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. detect target object and cut images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_floder = '/mnt/hdd1/Data/Competition/orchid/training'\n",
    "df_tr = pd.DataFrame({'filepath':glob.glob(os.path.join(data_floder,'*.jpg'))})\n",
    "df_tr['filename'] = df_tr['filepath'].map(lambda x: os.path.basename(x))\n",
    "\n",
    "#TODO: cut test_public\n",
    "#TODO: cut test_private\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = '/mnt/hdd1/Model/Competition/orchid/yolox/last_epoch_ckpt.pth'\n",
    "predictor = Predictor(conf=0.4, model_path=model_path)\n",
    "\n",
    "aug_folder=data_floder+'_aug'\n",
    "if not os.path.exists(aug_folder):\n",
    "    os.makedirs(aug_folder)\n",
    "    \n",
    "for r in tqdm(df_tr.itertuples()):\n",
    "    filepath= r.filepath\n",
    "    img_raw = cv2.imread(filepath)\n",
    "    img_h, img_w = img_raw.shape[:2]\n",
    "    cls, scores, bboxes_tlbr, boxes_tlwh = predictor.detect(img_raw)\n",
    "    if len(bboxes_tlbr)>0:\n",
    "        bboxes_tlbr, valid_idx = predictor.parse_bbox(bboxes_tlbr)\n",
    "        bboxes_tlbr = predictor.merge_bbox(bboxes_tlbr)\n",
    "        x1,y1,x2,y2 = np.array(bboxes_tlbr).astype(int)\n",
    "        x1 = np.clip(x1, 0, img_w)\n",
    "        y1 = np.clip(y1, 0, img_h)\n",
    "        x2 = np.clip(x2, 0, img_w)\n",
    "        y2 = np.clip(y2, 0, img_h)        \n",
    "        img_cut = img_raw[y1:y2,x1:x2]\n",
    "    else:\n",
    "        img_cut = img_raw\n",
    "    img = Image.fromarray(img_cut)\n",
    "    fname = 'aug_'+os.path.basename(filepath)\n",
    "    save_path = os.path.join(aug_folder,fname)    \n",
    "    img.save(save_path, quality=90)\n",
    "    \n",
    "ori_qty = len(glob.glob(os.path.join(data_floder,'*.jpg')))\n",
    "aug_qty = len(glob.glob(os.path.join(aug_folder,'*.jpg')))\n",
    "assert aug_qty == ori_qty, 'image qty not equal'    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def draw_boxes(image, box, adc, msg, color, thickness=8):\n",
    "    xmin, ymin, xmax, ymax = list(map(int, box))\n",
    "    label = f'{msg} score:{adc:.1f}'\n",
    "    font_size=0.8\n",
    "    ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_size, 2)\n",
    "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, thickness)\n",
    "    cv2.rectangle(image, (xmin, ymax - ret[1] - baseline), (xmin + ret[0], ymax), color, -1)\n",
    "    cv2.putText(image, label, (xmin, ymax - baseline), cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 255, 255), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/mnt/hdd1/Model/Competition/orchid/yolox/last_epoch_ckpt.pth'\n",
    "predictor = Predictor(conf=0.4, model_path=model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_floder = '/mnt/hdd1/Data/Competition/orchid/training'\n",
    "df_tr = pd.DataFrame({'filepath':glob.glob(os.path.join(data_floder,'*.jpg'))})\n",
    "df_tr['filename'] = df_tr['filepath'].map(lambda x: os.path.basename(x))\n",
    "\n",
    "for i in range(1000, 1010):\n",
    "    color = [211,199,178]\n",
    "    filepath = df_tr.iloc[i]['filepath']\n",
    "    img_raw = cv2.imread(filepath)\n",
    "    cls, scores, bboxes_tlbr, boxes_tlwh = predictor.detect(img_raw)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(131)\n",
    "    img_draw = img_raw.copy()\n",
    "    for i in range(len(bboxes_tlbr)):\n",
    "        draw_boxes(img_draw, bboxes_tlbr[i], scores[i], '', color)\n",
    "    plt.imshow(img_draw[:,:,::-1])\n",
    "\n",
    "    plt.subplot(132)\n",
    "    if len(bboxes_tlbr)>0:\n",
    "        bboxes_tlbr, valid_idx = predictor.parse_bbox(bboxes_tlbr)\n",
    "        scores = scores[valid_idx]\n",
    "    img_draw = img_raw.copy()\n",
    "    for i in range(len(bboxes_tlbr)):\n",
    "        draw_boxes(img_draw, bboxes_tlbr[i], scores[i], '', color)\n",
    "    plt.imshow(img_draw[:,:,::-1])    \n",
    "    \n",
    "    plt.subplot(133)\n",
    "    if len(bboxes_tlbr)>0:\n",
    "        bboxes_tlbr = predictor.merge_bbox(bboxes_tlbr)\n",
    "\n",
    "    img_draw = img_raw.copy()\n",
    "    if len(bboxes_tlbr)>0:\n",
    "        score = scores.mean()\n",
    "        draw_boxes(img_draw, bboxes_tlbr, score, '', color)\n",
    "    plt.imshow(img_draw[:,:,::-1])    \n",
    "        \n",
    "        \n",
    "    plt.show()\n",
    "    #print(cls, COCO_CLASSES[int(cls[0])], scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "trackID.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
